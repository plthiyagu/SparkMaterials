<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description></description><name>filetokafkatemplate</name><snippet><processGroups><id>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</id><parentGroupId>54006d1e-cb13-43fb-a56f-548d92c56344</parentGroupId><position><x>64.5</x><y>211.5</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>b0506d9f-0a59-4f8d-bf45-cf9d77c7aba9</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>7517f3d9-1a34-4da3-ba48-ef7df2b245b4</id><type>FUNNEL</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>Failure</selectedRelationships><selectedRelationships>No Retry</selectedRelationships><selectedRelationships>Original</selectedRelationships><selectedRelationships>Response</selectedRelationships><selectedRelationships>Retry</selectedRelationships><source><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>6327ff9f-2eb0-41f5-8a4d-6e46d2b77104</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>6e5d2f87-1d0e-4183-bad8-fa80ed8cd39a</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>46b6ac7a-d552-47b8-b215-e91db380cb87</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>7517f3d9-1a34-4da3-ba48-ef7df2b245b4</id><type>FUNNEL</type></source><zIndex>0</zIndex></connections><connections><id>46f1075e-afba-4a5d-9d09-d41f5fbad0aa</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>7517f3d9-1a34-4da3-ba48-ef7df2b245b4</id><type>FUNNEL</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>d9392b60-4edf-4906-9367-20fd4ea51384</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>b47ed63f-2da8-43fd-a535-5ce368573264</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>8e50d7c1-6a3f-4019-b4fe-1f84225470e7</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</groupId><id>d35693e3-9575-4d02-8117-7d9ee2105f52</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><funnels><id>7517f3d9-1a34-4da3-ba48-ef7df2b245b4</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><position><x>231.5</x><y>120.5</y></position></funnels><inputPorts><id>d9392b60-4edf-4906-9367-20fd4ea51384</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><position><x>-73.5</x><y>59.5</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>kafkagrpinport</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><processors><id>d35693e3-9575-4d02-8117-7d9ee2105f52</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><position><x>-139.1157202782569</x><y>190.88016361385195</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ZooKeeper Connection String</key><value><description>The Connection String to use in order to connect to ZooKeeper. This is often a comma-separated list of &lt;host&gt;:&lt;port&gt; combinations. For example, host1:2181,host2:2181,host3:2188</description><displayName>ZooKeeper Connection String</displayName><dynamic>false</dynamic><name>ZooKeeper Connection String</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Topic Name</key><value><description>The Kafka Topic to pull messages from</description><displayName>Topic Name</displayName><dynamic>false</dynamic><name>Topic Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Zookeeper Commit Frequency</key><value><defaultValue>60 secs</defaultValue><description>Specifies how often to communicate with ZooKeeper to indicate which messages have been pulled. A longer time period will result in better overall performance but can result in more data duplication if a NiFi node is lost</description><displayName>Zookeeper Commit Frequency</displayName><dynamic>false</dynamic><name>Zookeeper Commit Frequency</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Batch Size</key><value><defaultValue>1</defaultValue><description>Specifies the maximum number of messages to combine into a single FlowFile. These messages will be concatenated together with the &lt;Message Demarcator&gt; string placed between the content of each message. If the messages from Kafka should not be concatenated together, leave this value at 1.</description><displayName>Batch Size</displayName><dynamic>false</dynamic><name>Batch Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Message Demarcator</key><value><defaultValue>\n</defaultValue><description>Specifies the characters to use in order to demarcate multiple messages from Kafka. If the &lt;Batch Size&gt; property is set to 1, this value is ignored. Otherwise, for each two subsequent messages in the batch, this value will be placed in between them.</description><displayName>Message Demarcator</displayName><dynamic>false</dynamic><name>Message Demarcator</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Client Name</key><value><defaultValue>NiFi-d35693e3-9575-4d02-8117-7d9ee2105f52</defaultValue><description>Client Name to use when communicating with Kafka</description><displayName>Client Name</displayName><dynamic>false</dynamic><name>Client Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Group ID</key><value><defaultValue>d35693e3-9575-4d02-8117-7d9ee2105f52</defaultValue><description>A Group ID is used to identify consumers that are within the same consumer group</description><displayName>Group ID</displayName><dynamic>false</dynamic><name>Group ID</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kafka Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description>The amount of time to wait for a response from Kafka before determining that there is a communications error</description><displayName>Kafka Communications Timeout</displayName><dynamic>false</dynamic><name>Kafka Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>ZooKeeper Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description>The amount of time to wait for a response from ZooKeeper before determining that there is a communications error</description><displayName>ZooKeeper Communications Timeout</displayName><dynamic>false</dynamic><name>ZooKeeper Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Auto Offset Reset</key><value><allowableValues><displayName>smallest</displayName><value>smallest</value></allowableValues><allowableValues><displayName>largest</displayName><value>largest</value></allowableValues><defaultValue>largest</defaultValue><description>Automatically reset the offset to the smallest or largest offset available on the broker</description><displayName>Auto Offset Reset</displayName><dynamic>false</dynamic><name>Auto Offset Reset</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ZooKeeper Connection String</key><value>localhost:2181</value></entry><entry><key>Topic Name</key><value>tk1</value></entry><entry><key>Zookeeper Commit Frequency</key></entry><entry><key>Batch Size</key></entry><entry><key>Message Demarcator</key></entry><entry><key>Client Name</key></entry><entry><key>Group ID</key></entry><entry><key>Kafka Communications Timeout</key></entry><entry><key>ZooKeeper Communications Timeout</key></entry><entry><key>Auto Offset Reset</key><value>smallest</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>GetKafka</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles that are created are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.kafka.GetKafka</type></processors><processors><id>6327ff9f-2eb0-41f5-8a4d-6e46d2b77104</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><position><x>143.5</x><y>-71.5</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>HTTP Method</key><value><defaultValue>GET</defaultValue><description>HTTP request method (GET, POST, PUT, DELETE, HEAD, OPTIONS). Arbitrary methods are also supported. Methods other than POST and PUT will be sent without a message body.</description><displayName>HTTP Method</displayName><dynamic>false</dynamic><name>HTTP Method</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Remote URL</key><value><description>Remote URL which will be connected to, including scheme, host, port, path.</description><displayName>Remote URL</displayName><dynamic>false</dynamic><name>Remote URL</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SSL Context Service</key><value><description>The SSL Context Service used to provide client certificate information for TLS/SSL (https) connections.</description><displayName>SSL Context Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.ssl.SSLContextService</identifiesControllerService><name>SSL Context Service</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Connection Timeout</key><value><defaultValue>5 secs</defaultValue><description>Max wait time for connection to remote service.</description><displayName>Connection Timeout</displayName><dynamic>false</dynamic><name>Connection Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Read Timeout</key><value><defaultValue>15 secs</defaultValue><description>Max wait time for response from remote service.</description><displayName>Read Timeout</displayName><dynamic>false</dynamic><name>Read Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Include Date Header</key><value><allowableValues><displayName>True</displayName><value>True</value></allowableValues><allowableValues><displayName>False</displayName><value>False</value></allowableValues><defaultValue>True</defaultValue><description>Include an RFC-2616 Date header in the request.</description><displayName>Include Date Header</displayName><dynamic>false</dynamic><name>Include Date Header</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Follow Redirects</key><value><allowableValues><displayName>True</displayName><value>True</value></allowableValues><allowableValues><displayName>False</displayName><value>False</value></allowableValues><defaultValue>True</defaultValue><description>Follow HTTP redirects issued by remote server.</description><displayName>Follow Redirects</displayName><dynamic>false</dynamic><name>Follow Redirects</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attributes to Send</key><value><description>Regular expression that defines which attributes to send as HTTP headers in the request. If not defined, no attributes are sent as headers. Also any dynamic properties set will be sent as headers. The dynamic property key will be the header key and the dynamic property value will be interpreted as expression language will be the header value.</description><displayName>Attributes to Send</displayName><dynamic>false</dynamic><name>Attributes to Send</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Basic Authentication Username</key><value><description>The username to be used by the client to authenticate against the Remote URL.  Cannot include control characters (0-31), ':', or DEL (127).</description><displayName>Basic Authentication Username</displayName><dynamic>false</dynamic><name>Basic Authentication Username</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Basic Authentication Password</key><value><description>The password to be used by the client to authenticate against the Remote URL.</description><displayName>Basic Authentication Password</displayName><dynamic>false</dynamic><name>Basic Authentication Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Proxy Host</key><value><description>The fully qualified hostname or IP address of the proxy server</description><displayName>Proxy Host</displayName><dynamic>false</dynamic><name>Proxy Host</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Proxy Port</key><value><description>The port of the proxy server</description><displayName>Proxy Port</displayName><dynamic>false</dynamic><name>Proxy Port</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Put Response Body In Attribute</key><value><description>If set, the response body received back will be put into an attribute of the original FlowFile instead of a separate FlowFile. The attribute key to put to is determined by evaluating value of this property. </description><displayName>Put Response Body In Attribute</displayName><dynamic>false</dynamic><name>Put Response Body In Attribute</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Length To Put In Attribute</key><value><defaultValue>256</defaultValue><description>If routing the response body to an attribute of the original (by setting the &quot;Put response body in attribute&quot; property or by receiving an error status code), the number of characters put to the attribute value will be at most this amount. This is important because attributes are held in memory and large attributes will quickly cause out of memory issues. If the output goes longer than this value, it will be truncated to fit. Consider making this smaller if able.</description><displayName>Max Length To Put In Attribute</displayName><dynamic>false</dynamic><name>Max Length To Put In Attribute</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Digest Authentication</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Whether to communicate with the website using Digest Authentication. 'Basic Authentication Username' and 'Basic Authentication Password' are used for authentication.</description><displayName>Use Digest Authentication</displayName><dynamic>false</dynamic><name>Digest Authentication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Always Output Response</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Will force a response FlowFile to be generated and routed to the 'Response' relationship regardless of what the server status code received is or if the processor is configured to put the server response body in the request attribute. In the later configuration a request FlowFile with the response body in the attribute and a typical response FlowFile will be emitted to their respective relationships.</description><displayName>Always Output Response</displayName><dynamic>false</dynamic><name>Always Output Response</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Trusted Hostname</key><value><description>Bypass the normal truststore hostname verifier to allow the specified remote hostname as trusted. Enabling this property has MITM security implications, use wisely. Will still accept other connections based on the normal truststore hostname verifier. Only valid with SSL (HTTPS) connections.</description><displayName>Trusted Hostname</displayName><dynamic>false</dynamic><name>Trusted Hostname</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Add Response Headers to Request</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Enabling this property saves all the response headers to the original request. This may be when the response headers are needed but a response is not generated due to the status code received.</description><displayName>Add Response Headers to Request</displayName><dynamic>false</dynamic><name>Add Response Headers to Request</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Content-Type</key><value><defaultValue>${mime.type}</defaultValue><description>The Content-Type to specify for when content is being transmitted through a PUT or POST. In the case of an empty value after evaluating an expression language expression, Content-Type defaults to application/octet-stream</description><displayName>Content-Type</displayName><dynamic>false</dynamic><name>Content-Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Use Chunked Encoding</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>When POST'ing or PUT'ing content set this property to true in order to not pass the 'Content-length' header and instead send 'Transfer-Encoding' with a value of 'chunked'. This will enable the data transfer mechanism which was introduced in HTTP 1.1 to pass data of unknown lengths in chunks.</description><displayName>Use Chunked Encoding</displayName><dynamic>false</dynamic><name>Use Chunked Encoding</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Penalize on &quot;No Retry&quot;</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Enabling this property will penalize FlowFiles that are routed to the &quot;No Retry&quot; relationship.</description><displayName>Penalize on &quot;No Retry&quot;</displayName><dynamic>false</dynamic><name>Penalize on &quot;No Retry&quot;</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>HTTP Method</key><value>GET</value></entry><entry><key>Remote URL</key><value>https://api.randomuser.me/</value></entry><entry><key>SSL Context Service</key></entry><entry><key>Connection Timeout</key><value>5 secs</value></entry><entry><key>Read Timeout</key><value>15 secs</value></entry><entry><key>Include Date Header</key><value>True</value></entry><entry><key>Follow Redirects</key><value>True</value></entry><entry><key>Attributes to Send</key></entry><entry><key>Basic Authentication Username</key></entry><entry><key>Basic Authentication Password</key></entry><entry><key>Proxy Host</key></entry><entry><key>Proxy Port</key></entry><entry><key>Put Response Body In Attribute</key></entry><entry><key>Max Length To Put In Attribute</key><value>256</value></entry><entry><key>Digest Authentication</key><value>false</value></entry><entry><key>Always Output Response</key><value>false</value></entry><entry><key>Trusted Hostname</key></entry><entry><key>Add Response Headers to Request</key><value>false</value></entry><entry><key>Content-Type</key><value>${mime.type}</value></entry><entry><key>Use Chunked Encoding</key><value>false</value></entry><entry><key>Penalize on &quot;No Retry&quot;</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>InvokeHTTP</name><relationships><autoTerminate>false</autoTerminate><description>The original FlowFile will be routed on any type of connection failure, timeout or general exception. It will have new attributes detailing the request.</description><name>Failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The original FlowFile will be routed on any status code that should NOT be retried (1xx, 3xx, 4xx status codes).  It will have new attributes detailing the request.</description><name>No Retry</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The original FlowFile will be routed upon success (2xx status codes). It will have new attributes detailing the success of the request.</description><name>Original</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A Response FlowFile will be routed upon success (2xx status codes). If the 'Output Response Regardless' property is true then the response will be sent to this relationship regardless of the status code received.</description><name>Response</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The original FlowFile will be routed on any status code that can be retried (5xx status codes). It will have new attributes detailing the request.</description><name>Retry</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.InvokeHTTP</type></processors><processors><id>46b6ac7a-d552-47b8-b215-e91db380cb87</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><position><x>436.5</x><y>54.5</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Known Brokers</key><value><description>A comma-separated list of known Kafka Brokers in the format &lt;host&gt;:&lt;port&gt;</description><displayName>Known Brokers</displayName><dynamic>false</dynamic><name>Known Brokers</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Topic Name</key><value><description>The Kafka Topic of interest</description><displayName>Topic Name</displayName><dynamic>false</dynamic><name>Topic Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Strategy</key><value><allowableValues><description>Messages will be assigned partitions in a round-robin fashion, sending the first message to Partition 1, the next Partition to Partition 2, and so on, wrapping as necessary.</description><displayName>Round Robin</displayName><value>Round Robin</value></allowableValues><allowableValues><description>Messages will be assigned to random partitions.</description><displayName>Random</displayName><value>Random Robin</value></allowableValues><allowableValues><description>The &lt;Partition&gt; property will be used to determine the partition. All messages within the same FlowFile will be assigned to the same partition.</description><displayName>User-Defined</displayName><value>User-Defined</value></allowableValues><defaultValue>Round Robin</defaultValue><description>Specifies how messages should be partitioned when sent to Kafka</description><displayName>Partition Strategy</displayName><dynamic>false</dynamic><name>Partition Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Partition</key><value><description>Specifies which Kafka Partition to add the message to. If using a message delimiter, all messages in the same FlowFile will be sent to the same partition. If a partition is specified but is not valid, then all messages within the same FlowFile will use the same partition but it remains undefined which partition is used.</description><displayName>Partition</displayName><dynamic>false</dynamic><name>Partition</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Kafka Key</key><value><description>The Key to use for the Message</description><displayName>Kafka Key</displayName><dynamic>false</dynamic><name>Kafka Key</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Delivery Guarantee</key><value><allowableValues><description>FlowFile will be routed to success after successfully writing the content to a Kafka node, without waiting for a response. This provides the best performance but may result in data loss.</description><displayName>Best Effort</displayName><value>0</value></allowableValues><allowableValues><description>FlowFile will be routed to success if the message is received by a single Kafka node, whether or not it is replicated. This is faster than &lt;Guarantee Replicated Delivery&gt; but can result in data loss if a Kafka node crashes</description><displayName>Guarantee Single Node Delivery</displayName><value>1</value></allowableValues><allowableValues><description>FlowFile will be routed to failure unless the message is replicated to the appropriate number of Kafka Nodes according to the Topic configuration</description><displayName>Guarantee Replicated Delivery</displayName><value>all</value></allowableValues><defaultValue>0</defaultValue><description>Specifies the requirement for guaranteeing that a message is sent to Kafka</description><displayName>Delivery Guarantee</displayName><dynamic>false</dynamic><name>Delivery Guarantee</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Message Delimiter</key><value><description>Specifies the delimiter to use for splitting apart multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. Note that if messages are delimited and some messages for a given FlowFile are transferred successfully while others are not, the messages will be split into individual FlowFiles, such that those messages that were successfully sent are routed to the 'success' relationship while other messages are sent to the 'failure' relationship.</description><displayName>Message Delimiter</displayName><dynamic>false</dynamic><name>Message Delimiter</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Buffer Size</key><value><defaultValue>5 MB</defaultValue><description>The maximum amount of data to buffer in memory before sending to Kafka</description><displayName>Max Buffer Size</displayName><dynamic>false</dynamic><name>Max Buffer Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Record Size</key><value><defaultValue>1 MB</defaultValue><description>The maximum size that any individual record can be.</description><displayName>Max Record Size</displayName><dynamic>false</dynamic><name>Max Record Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Communications Timeout</key><value><defaultValue>30 secs</defaultValue><description>The amount of time to wait for a response from Kafka before determining that there is a communications error</description><displayName>Communications Timeout</displayName><dynamic>false</dynamic><name>Communications Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Async Batch Size</key><value><defaultValue>200</defaultValue><description>The number of messages to send in one batch. The producer will wait until either this number of messages are ready to send or &quot;Queue Buffering Max Time&quot; is reached. NOTE: This property will be ignored unless the 'Message Delimiter' property is specified.</description><displayName>Batch Size</displayName><dynamic>false</dynamic><name>Async Batch Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Queue Buffering Max Time</key><value><defaultValue>5 secs</defaultValue><description>Maximum time to buffer data before sending to Kafka. For example a setting of 100 ms will try to batch together 100 milliseconds' worth of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.</description><displayName>Queue Buffering Max Time</displayName><dynamic>false</dynamic><name>Queue Buffering Max Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression Codec</key><value><allowableValues><description>Compression will not be used for any topic.</description><displayName>None</displayName><value>none</value></allowableValues><allowableValues><description>Compress messages using GZIP</description><displayName>GZIP</displayName><value>gzip</value></allowableValues><allowableValues><description>Compress messages using Snappy</description><displayName>Snappy</displayName><value>snappy</value></allowableValues><defaultValue>none</defaultValue><description>This parameter allows you to specify the compression codec for all data generated by this producer.</description><displayName>Compression Codec</displayName><dynamic>false</dynamic><name>Compression Codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Client Name</key><value><description>Client Name to use when communicating with Kafka</description><displayName>Client Name</displayName><dynamic>false</dynamic><name>Client Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Known Brokers</key><value>localhost:9092</value></entry><entry><key>Topic Name</key><value>tk1</value></entry><entry><key>Partition Strategy</key><value>Round Robin</value></entry><entry><key>Partition</key></entry><entry><key>Kafka Key</key></entry><entry><key>Delivery Guarantee</key><value>0</value></entry><entry><key>Message Delimiter</key></entry><entry><key>Max Buffer Size</key><value>5 MB</value></entry><entry><key>Max Record Size</key><value>1 MB</value></entry><entry><key>Communications Timeout</key><value>30 secs</value></entry><entry><key>Async Batch Size</key><value>200</value></entry><entry><key>Queue Buffering Max Time</key><value>5 secs</value></entry><entry><key>Compression Codec</key><value>none</value></entry><entry><key>Client Name</key><value>nificlient</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutKafka</name><relationships><autoTerminate>true</autoTerminate><description>Any FlowFile that cannot be sent to Kafka will be routed to this Relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Any FlowFile that is successfully sent to Kafka will be routed to this Relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.kafka.PutKafka</type></processors><processors><id>8e50d7c1-6a3f-4019-b4fe-1f84225470e7</id><parentGroupId>bbd62b43-e1aa-46c0-9ea9-5dbfc8de6533</parentGroupId><position><x>336.93286132812506</x><y>183.829833984375</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/usr/local/hadoop/etc/hadoop/core-site.xml,/usr/local/hadoop/etc/hadoop/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/user/hduser/nifihttpkafkadata</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key><value>NONE</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>1</inputPortCount><invalidCount>0</invalidCount><name>kafkagrp</name><outputPortCount>0</outputPortCount><parent><id>54006d1e-cb13-43fb-a56f-548d92c56344</id><name>NiFi Flow</name></parent><runningCount>0</runningCount><stoppedCount>5</stoppedCount></processGroups><processGroups><id>13b46abc-e950-463b-8dfa-c9c86ff17585</id><parentGroupId>54006d1e-cb13-43fb-a56f-548d92c56344</parentGroupId><position><x>73.5</x><y>-26.5</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>f249960e-ec3a-4835-b2d3-7746e0d01537</id><parentGroupId>13b46abc-e950-463b-8dfa-c9c86ff17585</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>13b46abc-e950-463b-8dfa-c9c86ff17585</groupId><id>10c2b935-b9cd-4f02-aa1f-5a09a1ed9c20</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>13b46abc-e950-463b-8dfa-c9c86ff17585</groupId><id>0bdff28b-d14b-4e2d-9b5e-a827cc09b958</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>5e1d59d0-23f2-41cc-89af-92a3fbd5b66c</id><parentGroupId>13b46abc-e950-463b-8dfa-c9c86ff17585</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>13b46abc-e950-463b-8dfa-c9c86ff17585</groupId><id>c79c7276-4b65-41e8-b1cc-fe6ebc5bbf41</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>13b46abc-e950-463b-8dfa-c9c86ff17585</groupId><id>bdfbbf35-7e6c-437f-b422-c151d690d1dd</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>650da353-45a1-48e4-bf65-340bf13c42f7</id><parentGroupId>13b46abc-e950-463b-8dfa-c9c86ff17585</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>13b46abc-e950-463b-8dfa-c9c86ff17585</groupId><id>0bdff28b-d14b-4e2d-9b5e-a827cc09b958</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>13b46abc-e950-463b-8dfa-c9c86ff17585</groupId><id>bdfbbf35-7e6c-437f-b422-c151d690d1dd</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><outputPorts><id>c79c7276-4b65-41e8-b1cc-fe6ebc5bbf41</id><parentGroupId>13b46abc-e950-463b-8dfa-c9c86ff17585</parentGroupId><position><x>89.89819335937506</x><y>148.23156738281247</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>srcgrpport</name><state>STOPPED</state><type>OUTPUT_PORT</type></outputPorts><processors><id>0bdff28b-d14b-4e2d-9b5e-a827cc09b958</id><parentGroupId>13b46abc-e950-463b-8dfa-c9c86ff17585</parentGroupId><position><x>442.5</x><y>-16.5</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/home/hduser/nifidataoutput</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutFile</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>bdfbbf35-7e6c-437f-b422-c151d690d1dd</id><parentGroupId>13b46abc-e950-463b-8dfa-c9c86ff17585</parentGroupId><position><x>5.5</x><y>-70.5</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Input Directory</key><value><description>The input directory from which to pull files</description><displayName>Input Directory</displayName><dynamic>false</dynamic><name>Input Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>File Filter</key><value><defaultValue>[^\.].*</defaultValue><description>Only files whose names match the given regular expression will be picked up</description><displayName>File Filter</displayName><dynamic>false</dynamic><name>File Filter</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Path Filter</key><value><description>When Recurse Subdirectories is true, then only subdirectories whose path matches the given regular expression will be scanned</description><displayName>Path Filter</displayName><dynamic>false</dynamic><name>Path Filter</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Batch Size</key><value><defaultValue>10</defaultValue><description>The maximum number of files to pull in each iteration</description><displayName>Batch Size</displayName><dynamic>false</dynamic><name>Batch Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Source File</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If true, the file is not deleted after it has been copied to the Content Repository; this causes the file to be picked up continually and is useful for testing purposes.  If not keeping original NiFi will need write permissions on the directory it is pulling from otherwise it will ignore the file.</description><displayName>Keep Source File</displayName><dynamic>false</dynamic><name>Keep Source File</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Recurse Subdirectories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>Indicates whether or not to pull files from subdirectories</description><displayName>Recurse Subdirectories</displayName><dynamic>false</dynamic><name>Recurse Subdirectories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Polling Interval</key><value><defaultValue>0 sec</defaultValue><description>Indicates how long to wait before performing a directory listing</description><displayName>Polling Interval</displayName><dynamic>false</dynamic><name>Polling Interval</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Ignore Hidden Files</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>Indicates whether or not hidden files should be ignored</description><displayName>Ignore Hidden Files</displayName><dynamic>false</dynamic><name>Ignore Hidden Files</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum File Age</key><value><defaultValue>0 sec</defaultValue><description>The minimum age that a file must be in order to be pulled; any file younger than this amount of time (according to last modification date) will be ignored</description><displayName>Minimum File Age</displayName><dynamic>false</dynamic><name>Minimum File Age</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Age</key><value><description>The maximum age that a file must be in order to be pulled; any file older than this amount of time (according to last modification date) will be ignored</description><displayName>Maximum File Age</displayName><dynamic>false</dynamic><name>Maximum File Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum File Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size that a file must be in order to be pulled</description><displayName>Minimum File Size</displayName><dynamic>false</dynamic><name>Minimum File Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Size</key><value><description>The maximum size that a file can be in order to be pulled</description><displayName>Maximum File Size</displayName><dynamic>false</dynamic><name>Maximum File Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Input Directory</key><value>/home/hduser/nifisrcdata</value></entry><entry><key>File Filter</key><value>[^\.].*</value></entry><entry><key>Path Filter</key></entry><entry><key>Batch Size</key><value>10</value></entry><entry><key>Keep Source File</key><value>false</value></entry><entry><key>Recurse Subdirectories</key><value>true</value></entry><entry><key>Polling Interval</key><value>0 sec</value></entry><entry><key>Ignore Hidden Files</key><value>true</value></entry><entry><key>Minimum File Age</key><value>0 sec</value></entry><entry><key>Maximum File Age</key></entry><entry><key>Minimum File Size</key><value>0 B</value></entry><entry><key>Maximum File Size</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>GetFile</name><relationships><autoTerminate>false</autoTerminate><description>All files are routed to success</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.GetFile</type></processors><processors><id>10c2b935-b9cd-4f02-aa1f-5a09a1ed9c20</id><parentGroupId>13b46abc-e950-463b-8dfa-c9c86ff17585</parentGroupId><position><x>332.93286132812506</x><y>138.82983398437497</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/usr/local/hadoop/etc/hadoop/core-site.xml,/usr/local/hadoop/etc/hadoop/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/user/hduser/nifihdfsdata</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key><value>GZIP</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>0</inputPortCount><invalidCount>0</invalidCount><name>srcgrp</name><outputPortCount>1</outputPortCount><parent><id>54006d1e-cb13-43fb-a56f-548d92c56344</id><name>NiFi Flow</name></parent><runningCount>0</runningCount><stoppedCount>4</stoppedCount></processGroups></snippet><timestamp>02/12/2018 13:10:17 IST</timestamp></template>